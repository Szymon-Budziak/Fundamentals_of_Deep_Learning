{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification with the MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning excels at pattern (image) recognition by trial and error. By training a deep neural network with sufficeint data and providing the network with feedback on its performance via training, the network can identify, though a huge amount of iteration, its own set of conditions by which it can act in the correct way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The acurate image classification of the *MNIST dataset* is a collection of 70.000 grayscale images of handwritten digits from 0-9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation Data and Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with images for deep learning, weneed both the images themselves, usually denotead as `X`, and also, correct labels for these images, usually denoted as `Y`. Furthermore, we need `X` and `Y` values both for training the model and a separate set of `X` and `Y` values for validating the performence of the model after it has been trained. Therefore, we need 4 segments of data for the MNIST dataset:\n",
    " 1. `x_train` - images used for training the neural network\n",
    " 2. `y_train` - correct labels for the `x_train` images, used to evaluate the model's predictions during training\n",
    " 3. `x_valid` - images set aside for validating the performance of the model after it has been trained\n",
    " 4. `y_valid` - correct labels for the `x_valid` images, used to evaluate the model's predictions after it has been trained\n",
    " \n",
    " The process of preparing data for analysis is called *Data Engineering*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data into Memoey (with Keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras has many useful built in functions designed for the computer vision tasks. It is also a legitimate choice for deep learning in a professional setting due to its readability and efficiency. One of the many helpful features that Keras provides are modules containing many helper methods for many common datasets, including MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `mnist` module, we can easily load the MNIST data, already partitioned into images and labels for both training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data split between train and validation sets\n",
    "(x_train, y_train), (x_valid, y_valid) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the MNIST Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image itself is a 2D array with the dimensions 28x28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These 28x28 images are represented as a collection of unsigned 8-bit integer values\n",
    "0 and 255, the values corresponding with a pixel's grayscale value where 0 is black and \n",
    "255 is white and all other values are in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `matplotlib` we can render one of these grayscale images in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff11c0805e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = x_train[0]\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer what is this number is in the `y_train` data, which contains correct labels for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In deep learning, it is common that data needs to be transformed to be in the ideal state for training. There are 3 tasks we should perform with the data in preparation for training:\n",
    "1. Flatten the image data, to simplify the image input into the model.\n",
    "2. Normalize the image data, to make the image input values easier to work with for the model\n",
    "3. Categorize the labels, to make the label values easier to work with for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattening the Image Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible for a deep learning model to accept a 2-dimensional image but we are going to reshape each image into a single array of 784 continuous pixels. This is also called flattening the image. We will use the helper method `reshape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "x_valid = x_valid.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image has been reshaped and is now a collection of 1D arrays containing 784 pixel values each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,\n",
       "       126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
       "       253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n",
       "       253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,\n",
       "       253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,\n",
       "       253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,\n",
       "       183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
       "       229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n",
       "       221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,\n",
       "       213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,\n",
       "       219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,\n",
       "       226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "       136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the Image Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning models are better at dealing with floating point numbers between 0 and 1. Converting integer values to floating point values between 0 and 1 is called *normalization*. Here we will divide all the pixel values by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255\n",
    "x_valid = x_valid/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values are all floating point values between 0.0 and 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical encoding \\ Categorically Encoding the Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical encodingis a kind of transformation that modifies the data so that each value is a collection of all possible categories, with the actual category that this particular value is set as true.\n",
    "Categorical encoding is tranforming values which are intended to be understood as categorical labels into a representation that makes their categorical nature explicit to the model.\n",
    "\n",
    "Keras provides a utility to *categorically encode values* and here we use it to perform encoding for both the training and validation labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_categories = 10\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_categories)\n",
    "y_valid = keras.utils.to_categorical(y_valid, num_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data prepared for training, it is now time to create the model that we will train with the data. The first basic model will be made up of several layers and will be comprised of 3 main parts:\n",
    "1. An input layer, which will receive data in some expected format\n",
    "2. Several *hidden layers*, each comprised of many neurons. Each *neuron* will have the ability to affect the networks's guess with its weights, which are values that will be updated over many iterations as the network gets feedback on its performance and learns\n",
    "3. An output layer, which will depict the network's guess for a given image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanting the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Kera's *Sequential* model class to instantiate an instance of a model that will have a series of layers that data will pass through in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Input Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add the input layer which will be densely connected, meaning that each neuron in it, and its weights, will affect every neuron in the next layer. To do this with Keras, we use Kera's *Dense* layer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `units` argument specifies the number of neurons in the layer. Choosing the corect number of neurons is what puts the \"science\" in \"data science\" as it is a matter of capturing the statistical complexity of the dataset (we are going to use 512).\n",
    "\n",
    "We will use `relu` activation function, which in short, will help our network to learn how to make more sophisticated guesses about data than if it were required to make guesses based on some striclty linear function.\n",
    "\n",
    "The `input_shape` value specifies the shape of the incoming data which in our situation is a 1D array of 784 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=512, activation='relu', input_shape=(784,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Hidden Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will add an additional densely connected layer. These layers give the network more parameters to contibute towards its guesses, and therefore, more subtle opportunities for accurate learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units = 512, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Output Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will add an input layer. This layer uses activation function `softmax` which will result in each of the layer's values being a probability between 0 and 1 and will result in all the outputs of the layer adding to 1. In this case, since the network is to make a guess about a single image belonging to 1 of 10 possible categories, there will be 10 outputs. Each output gices the model's guess (a probability) that the image belongs to specific class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units = 10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras provides the model instance method *summary* which will print readable summary of a model. Note the number of trainable parameters. Each of these can be adjusted during training and will contribute towards the trained model's guesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final step we need to do before we can actually train our model with data to *compile* it. Here we specify a *loss function* which will be used for the model to undderstand how well it is performing during training. We also specify that becase we would like to track `accuracy` while the model trains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have prepared training and validation data and a model, it's time to train our model with our training data and verify it with its validation data. \"Training the model with data\" is often also called \"fitting a model to data\".\n",
    "\n",
    "When fitting (training) a model with Keras, we use the model's *fit* method. It expects the following arguments:\n",
    " - the training data\n",
    " - the labels for the training data\n",
    " - the number of times it should train on the entire training dataset (called an *epoch*)\n",
    " - the validation or test data and its labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.1940 - accuracy: 0.9420 - val_loss: 0.1040 - val_accuracy: 0.9708\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1025 - accuracy: 0.9744 - val_loss: 0.0986 - val_accuracy: 0.9742\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0861 - accuracy: 0.9805 - val_loss: 0.1125 - val_accuracy: 0.9752\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0738 - accuracy: 0.9836 - val_loss: 0.1390 - val_accuracy: 0.9768\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0644 - accuracy: 0.9861 - val_loss: 0.1460 - val_accuracy: 0.9800\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=5, verbose=1,\n",
    "                    validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observing accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the 5 epochs, notice the `accuracy` and `val_accuracy` scores. `accuracy` states how well the model did for the epoch on all the training data. `val_accuracy` states how well the model did on the validation data, which if you recall, was not used at all for training the model.\n",
    "\n",
    "The next step would be to use this model to classify new not-yer-seen handwritten images. This is called *inference*.\n",
    "\n",
    "MNIST is not only useful for its historical influence on Computer Vision but it's also a great *benchmark* and *debugging tool*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear the memory\n",
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, each neuron is tring to fit a line to some data. Below, we have some datapoints and a randomly drawn line using the equation y = mx + b."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try changing the `m` and the `b` in order to find the lowest possible loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 5\n",
    "b = 15\n",
    "\n",
    "x = np.array([0,  1,  2,  3,  4,  5,  6,  7,  8,  9])\n",
    "y = np.array([10, 20, 25, 30, 40, 45, 40, 50, 60, 55])\n",
    "y_hat = x*m+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.872983346207417\n"
     ]
    }
   ],
   "source": [
    "def get_rmse(x_data, y_data, m, b):\n",
    "    squared_error = 0\n",
    "    for i in range(len(x_data)):\n",
    "        y_hat = m*x_data[i]+b\n",
    "        squared_error += (y_data[i]-y_hat)**2\n",
    "    mse = squared_error / len(x_data)\n",
    "    return mse ** .5\n",
    "\n",
    "print(get_rmse(x, y, m, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  15.0\n"
     ]
    }
   ],
   "source": [
    "plt.plot(x, y, '.')\n",
    "plt.plot(x, y_hat, '-')\n",
    "plt.show()\n",
    "\n",
    "print(\"Loss: \", np.sum((y-y_hat)**2)/len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear the memory\n",
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
