{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fresh and rotten fruits recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train a new model that is able to recognize fresh and rotten fruit. We would like to train our model to be at least 92% accurate on the validation dataset.\n",
    "\n",
    "The dataset comes from Kaggle. You can download it [here](https://www.kaggle.com/sriramr/fruits-fresh-and-rotten-for-classification). This dataset is not in Date foler because it is too large. There are 6 categories of fruits: fresh apples, fresh oranges, fresh bananas, rotten apples, rotten oranges and rotten bananas. This means that our model will require an output layer of 6 neurons to do the categorization successfully. We will also need to compile the model with `categorical_crossentropy`, as we have more than two categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the ImageNet Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with model pretrained on ImageNet. We will load the model with the correct weights, set an input shape and choose to remove the last layer of the model.\n",
    "\n",
    "Notice: The images have three dimensions: a height and with and a number of channels. Because these pictures ale in color, there will be three channels for red, green and blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.VGG16(weights='imagenet',\n",
    "                                           input_shape=(224, 224, 3),\n",
    "                                           include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freze base model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will freeze the base model so that all the learning from the ImageNet dataset does not get destroyed in the initial training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add layers to model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will add layers to the pretrained model. We should pay attention to the last dense layer and make sure it has the correct number of neurons to classify the different types of fruit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inpts\n",
    "inputs = keras.Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "\n",
    "# Add pooling layer or flatten layer\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add final dense layer\n",
    "outputs = keras.layers.Dense(6, activation='softmax')(x)\n",
    "\n",
    "# Combine inputs and outputs to create model\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 14,717,766\n",
      "Trainable params: 3,078\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will compile the model with loss and metric options. Remember that we are training on a number of different categories, rather than a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=[keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augument the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try to augment the data to improve the dataset. It may be helpful to get 92% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=10,\n",
    "                            zoom_range=0.1,\n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            horizontal_flip=True,\n",
    "                            vertical_flip=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will load the train and validation datasets. We have to pick the right folders, as well as the right `target_size` of the images (it needs to match the height and width input of the model we have created)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10901 images belonging to 6 classes.\n",
      "Found 2698 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# load and iterate training dataset\n",
    "train_it = datagen.flow_from_directory('Data/fruits/train/',\n",
    "                                   target_size=(224, 224),\n",
    "                                   color_mode='rgb',\n",
    "                                   class_mode='categorical')\n",
    "\n",
    "# load and iterate validation dataset\n",
    "test_it = datagen.flow_from_directory('Data/fruits/test/',\n",
    "                                   target_size=(224, 224),\n",
    "                                   color_mode='rgb',\n",
    "                                   class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to train the model. We have to pass the `train` and `valid` iterators into the `fit` function, as well as setting our desired number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "10/10 [==============================] - 55s 5s/step - loss: 3.0986 - categorical_accuracy: 0.3551 - val_loss: 2.5571 - val_categorical_accuracy: 0.4583\n",
      "Epoch 2/15\n",
      "10/10 [==============================] - 56s 5s/step - loss: 1.8669 - categorical_accuracy: 0.5284 - val_loss: 1.9860 - val_categorical_accuracy: 0.5521\n",
      "Epoch 3/15\n",
      "10/10 [==============================] - 58s 6s/step - loss: 1.4790 - categorical_accuracy: 0.6108 - val_loss: 1.3753 - val_categorical_accuracy: 0.6667\n",
      "Epoch 4/15\n",
      "10/10 [==============================] - 59s 6s/step - loss: 1.3377 - categorical_accuracy: 0.6591 - val_loss: 1.3446 - val_categorical_accuracy: 0.6667\n",
      "Epoch 5/15\n",
      "10/10 [==============================] - 58s 5s/step - loss: 1.0725 - categorical_accuracy: 0.7017 - val_loss: 0.8836 - val_categorical_accuracy: 0.7812\n",
      "Epoch 6/15\n",
      "10/10 [==============================] - 57s 5s/step - loss: 1.0022 - categorical_accuracy: 0.7244 - val_loss: 0.5910 - val_categorical_accuracy: 0.8125\n",
      "Epoch 7/15\n",
      "10/10 [==============================] - 62s 6s/step - loss: 0.9883 - categorical_accuracy: 0.7585 - val_loss: 0.5366 - val_categorical_accuracy: 0.8021\n",
      "Epoch 8/15\n",
      "10/10 [==============================] - 59s 6s/step - loss: 0.5053 - categorical_accuracy: 0.8267 - val_loss: 0.6215 - val_categorical_accuracy: 0.8125\n",
      "Epoch 9/15\n",
      "10/10 [==============================] - 59s 6s/step - loss: 0.7582 - categorical_accuracy: 0.7955 - val_loss: 0.5380 - val_categorical_accuracy: 0.7812\n",
      "Epoch 10/15\n",
      "10/10 [==============================] - 60s 6s/step - loss: 0.6423 - categorical_accuracy: 0.8068 - val_loss: 0.5899 - val_categorical_accuracy: 0.8021\n",
      "Epoch 11/15\n",
      "10/10 [==============================] - 57s 5s/step - loss: 0.5284 - categorical_accuracy: 0.8466 - val_loss: 0.3967 - val_categorical_accuracy: 0.8958\n",
      "Epoch 12/15\n",
      "10/10 [==============================] - 57s 5s/step - loss: 0.5315 - categorical_accuracy: 0.8551 - val_loss: 0.4818 - val_categorical_accuracy: 0.8333\n",
      "Epoch 13/15\n",
      "10/10 [==============================] - 56s 5s/step - loss: 0.5314 - categorical_accuracy: 0.8580 - val_loss: 0.2808 - val_categorical_accuracy: 0.9062\n",
      "Epoch 14/15\n",
      "10/10 [==============================] - 56s 5s/step - loss: 0.3749 - categorical_accuracy: 0.8807 - val_loss: 0.3451 - val_categorical_accuracy: 0.9167\n",
      "Epoch 15/15\n",
      "10/10 [==============================] - 56s 5s/step - loss: 0.4364 - categorical_accuracy: 0.8807 - val_loss: 0.2961 - val_categorical_accuracy: 0.8958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4ce194ad90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_it,\n",
    "         validation_data=test_it,\n",
    "         steps_per_epoch=len(train_it)/train_it.batch_size,\n",
    "         validation_steps=len(test_it)/test_it.batch_size,\n",
    "         epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfreeze model for fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our model have not reached 92% validation accuracy we can makie fine tunning: unfreeze the base model and compile the model with a low learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# Compile the model with a low learning rate\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=0.00001),\n",
    "             loss = keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "             metrics=[keras.metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - 190s 18s/step - loss: 0.1493 - binary_accuracy: 0.9640 - val_loss: 0.1383 - val_binary_accuracy: 0.9722\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 190s 18s/step - loss: 0.1122 - binary_accuracy: 0.9749 - val_loss: 0.0580 - val_binary_accuracy: 0.9913\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 186s 18s/step - loss: 0.0826 - binary_accuracy: 0.9790 - val_loss: 0.0797 - val_binary_accuracy: 0.9688\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 193s 18s/step - loss: 0.0933 - binary_accuracy: 0.9777 - val_loss: 0.0581 - val_binary_accuracy: 0.9896\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 190s 18s/step - loss: 0.0606 - binary_accuracy: 0.9896 - val_loss: 0.1200 - val_binary_accuracy: 0.9688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4d3c519190>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_it,\n",
    "         validation_data=test_it,\n",
    "         steps_per_epoch=len(train_it)/train_it.batch_size,\n",
    "         validation_steps=len(test_it)/test_it.batch_size,\n",
    "         epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a model that has a validation accuracy higher than 92% and we can evaluate it. The evaluate function will return tuple, where the first value is our loss and the second values is our accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 11s 4s/step - loss: 0.1242 - binary_accuracy: 0.9705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12415876239538193, 0.9704861640930176]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_it, steps=len(test_it)/test_it.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear the GPU memory\n",
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
